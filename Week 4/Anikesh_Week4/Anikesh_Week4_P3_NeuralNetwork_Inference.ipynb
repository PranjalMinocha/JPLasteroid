{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a99edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20f5991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Asteroid_Modified.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5d842",
   "metadata": {},
   "source": [
    "# Test-Train Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d378ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2678cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = df.columns.values.tolist()\n",
    "input_features.remove('diameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90902b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[i for i in input_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce56661",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1dc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y , random_state=42, train_size=0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f73b8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X, y , random_state=42, train_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f4ea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96345, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b0862",
   "metadata": {},
   "source": [
    "# Prediction Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166e92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, median_absolute_error, explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b59e98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_metrics(prediction):\n",
    "    print(\"Mean Absolute Error :     \",mean_absolute_error(y_test, prediction))\n",
    "    print(\"Mean Squared Error :      \",mean_squared_error(y_test, prediction))\n",
    "    print(\"Median Absolute Error :   \",median_absolute_error(y_test, prediction))\n",
    "    print(\"Explained Variance Score :\",explained_variance_score(y_test, prediction))\n",
    "    print(\"r2-Score :                \",r2_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba3b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean:              \", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183a945",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f105330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 16:59:32.428815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59abce8",
   "metadata": {},
   "source": [
    "## DNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d005a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=X_train.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\", **options))\n",
    "    lr_adp = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,decay_steps=100,decay_rate=0.9)\n",
    "    optimizer = keras.optimizers.SGD(lr_adp,momentum=0.9)\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5bb8627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/zq1_k2t14hd7ykvvgsbb6f600000gn/T/ipykernel_22583/1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f3fac9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 16:59:45.833138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3011/3011 [==============================] - 9s 3ms/step - loss: 1274479.8750 - mean_absolute_error: 1274479.8750 - val_loss: 2.5538 - val_mean_absolute_error: 2.5538\n",
      "Epoch 2/100\n",
      "3011/3011 [==============================] - 9s 3ms/step - loss: 2.5495 - mean_absolute_error: 2.5495 - val_loss: 2.5419 - val_mean_absolute_error: 2.5419\n",
      "Epoch 3/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5413 - mean_absolute_error: 2.5413 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 4/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5407 - mean_absolute_error: 2.5407 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 5/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5407 - mean_absolute_error: 2.5407 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 6/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.5407 - mean_absolute_error: 2.5407 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 7/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5407 - mean_absolute_error: 2.5407 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 8/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5407 - mean_absolute_error: 2.5407 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 9/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5407 - mean_absolute_error: 2.5407 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1333ab9a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df8baed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e66da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9322813, 3.9322813, 3.9322813, ..., 3.9322813, 3.9322813,\n",
       "       3.9322813], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c800f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :      2.5385208360572893\n",
      "Mean Squared Error :       64.39782464999193\n",
      "Median Absolute Error :    1.3692812557220457\n",
      "Explained Variance Score : 0.33302221172337076\n",
      "r2-Score :                 0.3200793609938918\n"
     ]
    }
   ],
   "source": [
    "prediction_metrics(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371aa01",
   "metadata": {},
   "source": [
    "## DNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc659c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(n_hidden=1, n_neurons=30, learning_rate=0.05, input_shape=X_train.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\", **options))\n",
    "    lr_adp = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,decay_steps=100,decay_rate=0.9)\n",
    "    optimizer = keras.optimizers.SGD(lr_adp,momentum=0.9)\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046e792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/zq1_k2t14hd7ykvvgsbb6f600000gn/T/ipykernel_22583/1311852810.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg2 = keras.wrappers.scikit_learn.KerasRegressor(build_model2)\n"
     ]
    }
   ],
   "source": [
    "keras_reg2 = keras.wrappers.scikit_learn.KerasRegressor(build_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a33c417",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 1471209728.0000 - mean_absolute_error: 1471209728.0000 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 2/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7590 - mean_absolute_error: 2.7590 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 3/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7590 - mean_absolute_error: 2.7590 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 4/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7590 - mean_absolute_error: 2.7590 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 5/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7590 - mean_absolute_error: 2.7590 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 6/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7590 - mean_absolute_error: 2.7590 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 7/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7590 - mean_absolute_error: 2.7590 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133855f00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg2.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06cad82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = keras_reg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8e042ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.955882, 3.955882, 3.955882, ..., 3.955882, 3.955882, 3.955882],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38899e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :      2.7597784843957167\n",
      "Mean Squared Error :       97.03110376805024\n",
      "Median Absolute Error :    1.3771179275512697\n",
      "Explained Variance Score : 0.0\n",
      "r2-Score :                 -0.024467059811607905\n"
     ]
    }
   ],
   "source": [
    "prediction_metrics(y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f80dc3",
   "metadata": {},
   "source": [
    "## DNN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "907f9643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(n_hidden=1, n_neurons=25, learning_rate=1e-3, input_shape=X_train.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\", **options))\n",
    "    lr_adp = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,decay_steps=100,decay_rate=0.99)\n",
    "    optimizer = keras.optimizers.SGD(lr_adp,momentum=0.9999)\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb640fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/zq1_k2t14hd7ykvvgsbb6f600000gn/T/ipykernel_22583/3164829974.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg3 = keras.wrappers.scikit_learn.KerasRegressor(build_model3)\n"
     ]
    }
   ],
   "source": [
    "keras_reg3 = keras.wrappers.scikit_learn.KerasRegressor(build_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0604941d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 573010.0000 - mean_absolute_error: 573010.0000 - val_loss: 3.5316 - val_mean_absolute_error: 3.5316\n",
      "Epoch 2/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 3.5724 - mean_absolute_error: 3.5724 - val_loss: 3.6157 - val_mean_absolute_error: 3.6157\n",
      "Epoch 3/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 3.4677 - mean_absolute_error: 3.4677 - val_loss: 3.2657 - val_mean_absolute_error: 3.2657\n",
      "Epoch 4/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 3.3462 - mean_absolute_error: 3.3462 - val_loss: 3.1476 - val_mean_absolute_error: 3.1476\n",
      "Epoch 5/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 3.3330 - mean_absolute_error: 3.3330 - val_loss: 3.3201 - val_mean_absolute_error: 3.3201\n",
      "Epoch 6/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 3.2284 - mean_absolute_error: 3.2284 - val_loss: 3.4146 - val_mean_absolute_error: 3.4146\n",
      "Epoch 7/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 3.2126 - mean_absolute_error: 3.2126 - val_loss: 3.2419 - val_mean_absolute_error: 3.2419\n",
      "Epoch 8/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 3.0998 - mean_absolute_error: 3.0998 - val_loss: 3.3893 - val_mean_absolute_error: 3.3893\n",
      "Epoch 9/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 3.0836 - mean_absolute_error: 3.0836 - val_loss: 3.1198 - val_mean_absolute_error: 3.1198\n",
      "Epoch 10/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 3.0581 - mean_absolute_error: 3.0581 - val_loss: 3.2758 - val_mean_absolute_error: 3.2758\n",
      "Epoch 11/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9917 - mean_absolute_error: 2.9917 - val_loss: 2.8838 - val_mean_absolute_error: 2.8838\n",
      "Epoch 12/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9876 - mean_absolute_error: 2.9876 - val_loss: 3.1251 - val_mean_absolute_error: 3.1251\n",
      "Epoch 13/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9764 - mean_absolute_error: 2.9764 - val_loss: 2.7746 - val_mean_absolute_error: 2.7746\n",
      "Epoch 14/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9316 - mean_absolute_error: 2.9316 - val_loss: 3.0755 - val_mean_absolute_error: 3.0755\n",
      "Epoch 15/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9144 - mean_absolute_error: 2.9144 - val_loss: 3.0666 - val_mean_absolute_error: 3.0666\n",
      "Epoch 16/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8974 - mean_absolute_error: 2.8974 - val_loss: 2.8371 - val_mean_absolute_error: 2.8371\n",
      "Epoch 17/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9059 - mean_absolute_error: 2.9059 - val_loss: 2.9312 - val_mean_absolute_error: 2.9312\n",
      "Epoch 18/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8521 - mean_absolute_error: 2.8521 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 19/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8488 - mean_absolute_error: 2.8488 - val_loss: 2.7734 - val_mean_absolute_error: 2.7734\n",
      "Epoch 20/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8349 - mean_absolute_error: 2.8349 - val_loss: 2.7704 - val_mean_absolute_error: 2.7704\n",
      "Epoch 21/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8467 - mean_absolute_error: 2.8467 - val_loss: 2.7884 - val_mean_absolute_error: 2.7884\n",
      "Epoch 22/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8122 - mean_absolute_error: 2.8122 - val_loss: 2.8693 - val_mean_absolute_error: 2.8693\n",
      "Epoch 23/100\n",
      "3011/3011 [==============================] - 10s 3ms/step - loss: 2.7897 - mean_absolute_error: 2.7897 - val_loss: 2.7964 - val_mean_absolute_error: 2.7964\n",
      "Epoch 24/100\n",
      "3011/3011 [==============================] - 8s 3ms/step - loss: 2.8301 - mean_absolute_error: 2.8301 - val_loss: 2.8132 - val_mean_absolute_error: 2.8132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133856440>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg3.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0a2f6cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = keras_reg3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2da883a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.500564, 4.500564, 4.500564, ..., 4.500564, 4.500564, 4.500564],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e71535dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :      2.8136640159658874\n",
      "Mean Squared Error :       95.66945433705428\n",
      "Median Absolute Error :    1.5865640983581542\n",
      "Explained Variance Score : 0.0\n",
      "r2-Score :                 -0.010090587372407311\n"
     ]
    }
   ],
   "source": [
    "prediction_metrics(y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222fa30f",
   "metadata": {},
   "source": [
    "## DNN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f54bff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model4(n_hidden=1, n_neurons=50, learning_rate=0.01, input_shape=X_train.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\", **options))\n",
    "    lr_adp = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,decay_steps=100,decay_rate=0.9)\n",
    "    optimizer = keras.optimizers.SGD(lr_adp,momentum=0.999)\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e459804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/zq1_k2t14hd7ykvvgsbb6f600000gn/T/ipykernel_22583/3055908056.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg4 = keras.wrappers.scikit_learn.KerasRegressor(build_model4)\n"
     ]
    }
   ],
   "source": [
    "keras_reg4 = keras.wrappers.scikit_learn.KerasRegressor(build_model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61b6fc7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 48590248.0000 - mean_absolute_error: 48590248.0000 - val_loss: 3.5975 - val_mean_absolute_error: 3.5975\n",
      "Epoch 2/100\n",
      "3011/3011 [==============================] - 8s 3ms/step - loss: 3.1440 - mean_absolute_error: 3.1440 - val_loss: 2.7704 - val_mean_absolute_error: 2.7704\n",
      "Epoch 3/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.8584 - mean_absolute_error: 2.8584 - val_loss: 2.7666 - val_mean_absolute_error: 2.7666\n",
      "Epoch 4/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.7751 - mean_absolute_error: 2.7751 - val_loss: 2.7892 - val_mean_absolute_error: 2.7892\n",
      "Epoch 5/100\n",
      "3011/3011 [==============================] - 9s 3ms/step - loss: 2.7816 - mean_absolute_error: 2.7816 - val_loss: 2.7894 - val_mean_absolute_error: 2.7894\n",
      "Epoch 6/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.7815 - mean_absolute_error: 2.7815 - val_loss: 2.7893 - val_mean_absolute_error: 2.7893\n",
      "Epoch 7/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.7815 - mean_absolute_error: 2.7815 - val_loss: 2.7893 - val_mean_absolute_error: 2.7893\n",
      "Epoch 8/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.7815 - mean_absolute_error: 2.7815 - val_loss: 2.7893 - val_mean_absolute_error: 2.7893\n",
      "Epoch 9/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.7815 - mean_absolute_error: 2.7815 - val_loss: 2.7893 - val_mean_absolute_error: 2.7893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133d93400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg4.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb8b975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = keras_reg4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9417ba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6142397, 3.6142397, 3.6142397, ..., 3.6142397, 3.6142397,\n",
       "       3.6142397], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17b93592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :      2.780967273249466\n",
      "Mean Squared Error :       98.18798080132058\n",
      "Median Absolute Error :    1.2982396926879884\n",
      "Explained Variance Score : 0.0\n",
      "r2-Score :                 -0.03668151854507906\n"
     ]
    }
   ],
   "source": [
    "prediction_metrics(y_pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120902c",
   "metadata": {},
   "source": [
    "## DNN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ed7d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model5(n_hidden=1, n_neurons=50, learning_rate=0.1, input_shape=X_train.shape[1:]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\", **options))\n",
    "    lr_adp = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,decay_steps=100,decay_rate=0.99)\n",
    "    optimizer = keras.optimizers.SGD(lr_adp,momentum=0.999)\n",
    "    model.compile(loss=\"mean_absolute_error\", optimizer=optimizer, metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "739dde82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/zq1_k2t14hd7ykvvgsbb6f600000gn/T/ipykernel_22583/716683303.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg5 = keras.wrappers.scikit_learn.KerasRegressor(build_model5)\n"
     ]
    }
   ],
   "source": [
    "keras_reg5 = keras.wrappers.scikit_learn.KerasRegressor(build_model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9a7a785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 7929648128.0000 - mean_absolute_error: 7929648128.0000 - val_loss: 2.7714 - val_mean_absolute_error: 2.7714\n",
      "Epoch 2/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 3.2095 - mean_absolute_error: 3.2095 - val_loss: 2.7760 - val_mean_absolute_error: 2.7760\n",
      "Epoch 3/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.9684 - mean_absolute_error: 2.9684 - val_loss: 4.2349 - val_mean_absolute_error: 4.2349\n",
      "Epoch 4/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 3.1799 - mean_absolute_error: 3.1799 - val_loss: 2.7994 - val_mean_absolute_error: 2.7994\n",
      "Epoch 5/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.8494 - mean_absolute_error: 2.8494 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 6/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.8304 - mean_absolute_error: 2.8304 - val_loss: 2.7822 - val_mean_absolute_error: 2.7822\n",
      "Epoch 7/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.8044 - mean_absolute_error: 2.8044 - val_loss: 2.8655 - val_mean_absolute_error: 2.8655\n",
      "Epoch 8/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.8473 - mean_absolute_error: 2.8473 - val_loss: 2.8073 - val_mean_absolute_error: 2.8073\n",
      "Epoch 9/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7930 - mean_absolute_error: 2.7930 - val_loss: 2.8689 - val_mean_absolute_error: 2.8689\n",
      "Epoch 10/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7980 - mean_absolute_error: 2.7980 - val_loss: 2.7701 - val_mean_absolute_error: 2.7701\n",
      "Epoch 11/100\n",
      "3011/3011 [==============================] - 6s 2ms/step - loss: 2.7857 - mean_absolute_error: 2.7857 - val_loss: 2.7795 - val_mean_absolute_error: 2.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1340c7f40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg5.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cefa34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = keras_reg5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c90bcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.69353, 3.69353, 3.69353, ..., 3.69353, 3.69353, 3.69353],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a48014ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :      2.77198418081098\n",
      "Mean Squared Error :       97.89868392560474\n",
      "Median Absolute Error :    1.3115300827026366\n",
      "Explained Variance Score : 0.0\n",
      "r2-Score :                 -0.03362708436708872\n"
     ]
    }
   ],
   "source": [
    "prediction_metrics(y_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0e016",
   "metadata": {},
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d11d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c77dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distr = { \"n_hidden\": [0, 1, 2, 3], \"n_neurons\": np.arange(1, 100), \"learning_rate\": reciprocal(3e-4, 3e-2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca319988",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distr, n_iter=10, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4478a8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 599927616.0000 - mean_absolute_error: 599927616.0000 - val_loss: 242112464.0000 - val_mean_absolute_error: 242112464.0000\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 67895304.0000 - mean_absolute_error: 67895304.0000 - val_loss: 8420909.0000 - val_mean_absolute_error: 8420909.0000\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 8179938.5000 - mean_absolute_error: 8179938.5000 - val_loss: 725074.0625 - val_mean_absolute_error: 725074.0625\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 962221.7500 - mean_absolute_error: 962221.7500 - val_loss: 608339.3750 - val_mean_absolute_error: 608339.3750\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 100159.2422 - mean_absolute_error: 100159.2422 - val_loss: 21538.0430 - val_mean_absolute_error: 21538.0430\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 23890.8301 - mean_absolute_error: 23890.8301 - val_loss: 21301.2930 - val_mean_absolute_error: 21301.2930\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21429.0527 - mean_absolute_error: 21429.0527 - val_loss: 21254.3555 - val_mean_absolute_error: 21254.3555\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21243.2852 - mean_absolute_error: 21243.2852 - val_loss: 21189.7422 - val_mean_absolute_error: 21189.7422\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21222.5469 - mean_absolute_error: 21222.5469 - val_loss: 21187.8086 - val_mean_absolute_error: 21187.8086\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21219.4727 - mean_absolute_error: 21219.4727 - val_loss: 21187.7578 - val_mean_absolute_error: 21187.7578\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21218.8535 - mean_absolute_error: 21218.8535 - val_loss: 21187.7715 - val_mean_absolute_error: 21187.7715\n",
      "Epoch 12/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21218.7188 - mean_absolute_error: 21218.7188 - val_loss: 21187.7676 - val_mean_absolute_error: 21187.7676\n",
      "Epoch 13/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21218.6973 - mean_absolute_error: 21218.6973 - val_loss: 21187.7695 - val_mean_absolute_error: 21187.7695\n",
      "Epoch 14/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21218.7422 - mean_absolute_error: 21218.7422 - val_loss: 21187.7656 - val_mean_absolute_error: 21187.7656\n",
      "1004/1004 [==============================] - 2s 1ms/step - loss: 21177.0762 - mean_absolute_error: 21177.0762\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 569040832.0000 - mean_absolute_error: 569040832.0000 - val_loss: 26838940.0000 - val_mean_absolute_error: 26838940.0000\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 69766184.0000 - mean_absolute_error: 69766184.0000 - val_loss: 22530968.0000 - val_mean_absolute_error: 22530968.0000\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 9351249.0000 - mean_absolute_error: 9351249.0000 - val_loss: 221161.4531 - val_mean_absolute_error: 221161.4531\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 1076028.7500 - mean_absolute_error: 1076028.7500 - val_loss: 390533.4688 - val_mean_absolute_error: 390533.4688\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 87316.3516 - mean_absolute_error: 87316.3516 - val_loss: 49852.8359 - val_mean_absolute_error: 49852.8359\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 16532.5547 - mean_absolute_error: 16532.5547 - val_loss: 15325.1221 - val_mean_absolute_error: 15325.1221\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14706.5537 - mean_absolute_error: 14706.5537 - val_loss: 14474.7275 - val_mean_absolute_error: 14474.7275\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14536.0000 - mean_absolute_error: 14536.0000 - val_loss: 14465.4785 - val_mean_absolute_error: 14465.4785\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14513.2217 - mean_absolute_error: 14513.2217 - val_loss: 14463.8525 - val_mean_absolute_error: 14463.8525\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14510.6963 - mean_absolute_error: 14510.6963 - val_loss: 14463.2744 - val_mean_absolute_error: 14463.2744\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14510.2480 - mean_absolute_error: 14510.2480 - val_loss: 14463.2666 - val_mean_absolute_error: 14463.2666\n",
      "Epoch 12/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14510.1250 - mean_absolute_error: 14510.1250 - val_loss: 14463.2715 - val_mean_absolute_error: 14463.2715\n",
      "Epoch 13/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14510.1172 - mean_absolute_error: 14510.1172 - val_loss: 14463.2666 - val_mean_absolute_error: 14463.2666\n",
      "Epoch 14/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14510.0928 - mean_absolute_error: 14510.0928 - val_loss: 14463.2695 - val_mean_absolute_error: 14463.2695\n",
      "Epoch 15/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 14510.1250 - mean_absolute_error: 14510.1250 - val_loss: 14463.2715 - val_mean_absolute_error: 14463.2715\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 14574.4395 - mean_absolute_error: 14574.4395\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 615049152.0000 - mean_absolute_error: 615049152.0000 - val_loss: 202552656.0000 - val_mean_absolute_error: 202552656.0000\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 74758080.0000 - mean_absolute_error: 74758080.0000 - val_loss: 10783978.0000 - val_mean_absolute_error: 10783978.0000\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 8289706.0000 - mean_absolute_error: 8289706.0000 - val_loss: 1532214.2500 - val_mean_absolute_error: 1532214.2500\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 966645.0625 - mean_absolute_error: 966645.0625 - val_loss: 70204.3359 - val_mean_absolute_error: 70204.3359\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 91779.6328 - mean_absolute_error: 91779.6328 - val_loss: 50144.9453 - val_mean_absolute_error: 50144.9453\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 23833.8418 - mean_absolute_error: 23833.8418 - val_loss: 21719.1348 - val_mean_absolute_error: 21719.1348\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21925.9883 - mean_absolute_error: 21925.9883 - val_loss: 21646.1816 - val_mean_absolute_error: 21646.1816\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21725.6641 - mean_absolute_error: 21725.6641 - val_loss: 21640.3926 - val_mean_absolute_error: 21640.3926\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 21700.6133 - mean_absolute_error: 21700.6133 - val_loss: 21634.3477 - val_mean_absolute_error: 21634.3477\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 21698.2441 - mean_absolute_error: 21698.2441 - val_loss: 21634.4980 - val_mean_absolute_error: 21634.4980\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 21697.6074 - mean_absolute_error: 21697.6074 - val_loss: 21634.5527 - val_mean_absolute_error: 21634.5527\n",
      "Epoch 12/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 21697.5156 - mean_absolute_error: 21697.5156 - val_loss: 21634.5527 - val_mean_absolute_error: 21634.5527\n",
      "Epoch 13/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 21697.5469 - mean_absolute_error: 21697.5469 - val_loss: 21634.5566 - val_mean_absolute_error: 21634.5566\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 21630.2266 - mean_absolute_error: 21630.2266\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008/2008 [==============================] - 5s 3ms/step - loss: 331186.4375 - mean_absolute_error: 331186.4375 - val_loss: 2.5972 - val_mean_absolute_error: 2.5972\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5767 - mean_absolute_error: 2.5767 - val_loss: 2.5710 - val_mean_absolute_error: 2.5710\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5627 - mean_absolute_error: 2.5627 - val_loss: 2.5683 - val_mean_absolute_error: 2.5683\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5618 - mean_absolute_error: 2.5618 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 12/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5615 - mean_absolute_error: 2.5615 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5653 - mean_absolute_error: 2.5653\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 707155.5625 - mean_absolute_error: 707155.5625 - val_loss: 2.5954 - val_mean_absolute_error: 2.5954\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5855 - mean_absolute_error: 2.5855 - val_loss: 2.5703 - val_mean_absolute_error: 2.5703\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5723 - mean_absolute_error: 2.5723 - val_loss: 2.5683 - val_mean_absolute_error: 2.5683\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5705 - mean_absolute_error: 2.5705 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5680 - val_mean_absolute_error: 2.5680\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5480 - mean_absolute_error: 2.5480\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 339590.5938 - mean_absolute_error: 339590.5938 - val_loss: 2.6131 - val_mean_absolute_error: 2.6131\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5728 - mean_absolute_error: 2.5728 - val_loss: 2.5765 - val_mean_absolute_error: 2.5765\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5627 - mean_absolute_error: 2.5627 - val_loss: 2.5737 - val_mean_absolute_error: 2.5737\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5608 - mean_absolute_error: 2.5608 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5605 - mean_absolute_error: 2.5605 - val_loss: 2.5731 - val_mean_absolute_error: 2.5731\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5812 - mean_absolute_error: 2.5812\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 123.2064 - mean_absolute_error: 123.2064 - val_loss: 2.8283 - val_mean_absolute_error: 2.8283\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.8011 - mean_absolute_error: 2.8011 - val_loss: 2.8032 - val_mean_absolute_error: 2.8032\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7921 - mean_absolute_error: 2.7921 - val_loss: 2.8009 - val_mean_absolute_error: 2.8009\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7911 - mean_absolute_error: 2.7911 - val_loss: 2.8007 - val_mean_absolute_error: 2.8007\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7910 - mean_absolute_error: 2.7910 - val_loss: 2.8007 - val_mean_absolute_error: 2.8007\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7910 - mean_absolute_error: 2.7910 - val_loss: 2.8007 - val_mean_absolute_error: 2.8007\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7910 - mean_absolute_error: 2.7910 - val_loss: 2.8007 - val_mean_absolute_error: 2.8007\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7910 - mean_absolute_error: 2.7910 - val_loss: 2.8007 - val_mean_absolute_error: 2.8007\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7910 - mean_absolute_error: 2.7910 - val_loss: 2.8007 - val_mean_absolute_error: 2.8007\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7951 - mean_absolute_error: 2.7951\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 52.6747 - mean_absolute_error: 52.6747 - val_loss: 2.8306 - val_mean_absolute_error: 2.8306\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.8100 - mean_absolute_error: 2.8100 - val_loss: 2.8058 - val_mean_absolute_error: 2.8058\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.8016 - mean_absolute_error: 2.8016 - val_loss: 2.8035 - val_mean_absolute_error: 2.8035\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.8007 - mean_absolute_error: 2.8007 - val_loss: 2.8033 - val_mean_absolute_error: 2.8033\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.8006 - mean_absolute_error: 2.8006 - val_loss: 2.8032 - val_mean_absolute_error: 2.8032\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.8006 - mean_absolute_error: 2.8006 - val_loss: 2.8032 - val_mean_absolute_error: 2.8032\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.8006 - mean_absolute_error: 2.8006 - val_loss: 2.8032 - val_mean_absolute_error: 2.8032\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.8006 - mean_absolute_error: 2.8006 - val_loss: 2.8032 - val_mean_absolute_error: 2.8032\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.8006 - mean_absolute_error: 2.8006 - val_loss: 2.8032 - val_mean_absolute_error: 2.8032\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7834 - mean_absolute_error: 2.7834\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 13.1436 - mean_absolute_error: 13.1436 - val_loss: 2.8296 - val_mean_absolute_error: 2.8296\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.7985 - mean_absolute_error: 2.7985 - val_loss: 2.8042 - val_mean_absolute_error: 2.8042\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7899 - mean_absolute_error: 2.7899 - val_loss: 2.8020 - val_mean_absolute_error: 2.8020\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7890 - mean_absolute_error: 2.7890 - val_loss: 2.8018 - val_mean_absolute_error: 2.8018\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7889 - mean_absolute_error: 2.7889 - val_loss: 2.8018 - val_mean_absolute_error: 2.8018\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7889 - mean_absolute_error: 2.7889 - val_loss: 2.8018 - val_mean_absolute_error: 2.8018\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7889 - mean_absolute_error: 2.7889 - val_loss: 2.8018 - val_mean_absolute_error: 2.8018\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7889 - mean_absolute_error: 2.7889 - val_loss: 2.8018 - val_mean_absolute_error: 2.8018\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7889 - mean_absolute_error: 2.7889 - val_loss: 2.8018 - val_mean_absolute_error: 2.8018\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.8024 - mean_absolute_error: 2.8024\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 8761270.0000 - mean_absolute_error: 8761270.0000 - val_loss: 2.7201 - val_mean_absolute_error: 2.7201\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6807 - mean_absolute_error: 2.6807 - val_loss: 2.6764 - val_mean_absolute_error: 2.6764\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.7273 - mean_absolute_error: 2.7273 - val_loss: 2.6812 - val_mean_absolute_error: 2.6812\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6680 - mean_absolute_error: 2.6680 - val_loss: 2.6809 - val_mean_absolute_error: 2.6809\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6678 - mean_absolute_error: 2.6678 - val_loss: 2.6809 - val_mean_absolute_error: 2.6809\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6678 - mean_absolute_error: 2.6678 - val_loss: 2.6809 - val_mean_absolute_error: 2.6809\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7107 - mean_absolute_error: 2.7107\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 5667840.5000 - mean_absolute_error: 5667840.5000 - val_loss: 2.6210 - val_mean_absolute_error: 2.6210\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6105 - mean_absolute_error: 2.6105 - val_loss: 2.5739 - val_mean_absolute_error: 2.5739\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5725 - mean_absolute_error: 2.5725 - val_loss: 2.5622 - val_mean_absolute_error: 2.5622\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.5665 - mean_absolute_error: 2.5665 - val_loss: 2.5611 - val_mean_absolute_error: 2.5611\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5657 - mean_absolute_error: 2.5657 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "Epoch 12/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5656 - mean_absolute_error: 2.5656 - val_loss: 2.5610 - val_mean_absolute_error: 2.5610\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5368 - mean_absolute_error: 2.5368\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 3569911.5000 - mean_absolute_error: 3569911.5000 - val_loss: 2.6086 - val_mean_absolute_error: 2.6086\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5862 - mean_absolute_error: 2.5862 - val_loss: 2.5659 - val_mean_absolute_error: 2.5659\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5522 - mean_absolute_error: 2.5522 - val_loss: 2.5620 - val_mean_absolute_error: 2.5620\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5486 - mean_absolute_error: 2.5486 - val_loss: 2.5614 - val_mean_absolute_error: 2.5614\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5481 - mean_absolute_error: 2.5481 - val_loss: 2.5613 - val_mean_absolute_error: 2.5613\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5480 - mean_absolute_error: 2.5480 - val_loss: 2.5613 - val_mean_absolute_error: 2.5613\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5480 - mean_absolute_error: 2.5480 - val_loss: 2.5613 - val_mean_absolute_error: 2.5613\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5480 - mean_absolute_error: 2.5480 - val_loss: 2.5613 - val_mean_absolute_error: 2.5613\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5480 - mean_absolute_error: 2.5480 - val_loss: 2.5613 - val_mean_absolute_error: 2.5613\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5737 - mean_absolute_error: 2.5737\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 11781120.0000 - mean_absolute_error: 11781120.0000 - val_loss: 2.5997 - val_mean_absolute_error: 2.5997\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5655 - mean_absolute_error: 2.5655 - val_loss: 2.5458 - val_mean_absolute_error: 2.5458\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5364 - mean_absolute_error: 2.5364 - val_loss: 2.5410 - val_mean_absolute_error: 2.5410\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5327 - mean_absolute_error: 2.5327 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5322 - mean_absolute_error: 2.5322 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5321 - mean_absolute_error: 2.5321 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5320 - mean_absolute_error: 2.5320 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5320 - mean_absolute_error: 2.5320 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5320 - mean_absolute_error: 2.5320 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5320 - mean_absolute_error: 2.5320 - val_loss: 2.5409 - val_mean_absolute_error: 2.5409\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5504 - mean_absolute_error: 2.5504\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 15447720.0000 - mean_absolute_error: 15447720.0000 - val_loss: 2.6045 - val_mean_absolute_error: 2.6045\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 3.2210 - mean_absolute_error: 3.2210 - val_loss: 2.6795 - val_mean_absolute_error: 2.6795\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6749 - mean_absolute_error: 2.6749 - val_loss: 2.6771 - val_mean_absolute_error: 2.6771\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6736 - mean_absolute_error: 2.6736 - val_loss: 2.6769 - val_mean_absolute_error: 2.6769\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6734 - mean_absolute_error: 2.6734 - val_loss: 2.6769 - val_mean_absolute_error: 2.6769\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.6598 - mean_absolute_error: 2.6598\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 603658.5000 - mean_absolute_error: 603658.5000 - val_loss: 2.6871 - val_mean_absolute_error: 2.6871\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6761 - mean_absolute_error: 2.6761 - val_loss: 2.6745 - val_mean_absolute_error: 2.6745\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6648 - mean_absolute_error: 2.6648 - val_loss: 2.6718 - val_mean_absolute_error: 2.6718\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6631 - mean_absolute_error: 2.6631 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "Epoch 12/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6628 - mean_absolute_error: 2.6628 - val_loss: 2.6716 - val_mean_absolute_error: 2.6716\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.6651 - mean_absolute_error: 2.6651\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 458599366656.0000 - mean_absolute_error: 458599366656.0000 - val_loss: 2.7650 - val_mean_absolute_error: 2.7650\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7553 - mean_absolute_error: 2.7553 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7552 - mean_absolute_error: 2.7552 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7668 - mean_absolute_error: 2.7668\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 70179537983373312.0000 - mean_absolute_error: 70179537983373312.0000 - val_loss: 2.7647 - val_mean_absolute_error: 2.7647\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7667 - mean_absolute_error: 2.7667 - val_loss: 2.7646 - val_mean_absolute_error: 2.7646\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7665 - mean_absolute_error: 2.7665 - val_loss: 2.7645 - val_mean_absolute_error: 2.7645\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7664 - mean_absolute_error: 2.7664 - val_loss: 2.7645 - val_mean_absolute_error: 2.7645\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.7664 - mean_absolute_error: 2.7664 - val_loss: 2.7645 - val_mean_absolute_error: 2.7645\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7664 - mean_absolute_error: 2.7664 - val_loss: 2.7645 - val_mean_absolute_error: 2.7645\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7664 - mean_absolute_error: 2.7664 - val_loss: 2.7645 - val_mean_absolute_error: 2.7645\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7664 - mean_absolute_error: 2.7664 - val_loss: 2.7645 - val_mean_absolute_error: 2.7645\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7442 - mean_absolute_error: 2.7442\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 7062883467983809535677562880.0000 - mean_absolute_error: 7062883467983809535677562880.0000 - val_loss: 3.0067 - val_mean_absolute_error: 3.0067\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7555 - mean_absolute_error: 2.7555 - val_loss: 3.0069 - val_mean_absolute_error: 3.0069\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7554 - mean_absolute_error: 2.7554 - val_loss: 3.0068 - val_mean_absolute_error: 3.0068\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7554 - mean_absolute_error: 2.7554 - val_loss: 3.0068 - val_mean_absolute_error: 3.0068\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7554 - mean_absolute_error: 2.7554 - val_loss: 3.0068 - val_mean_absolute_error: 3.0068\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 3.0778 - mean_absolute_error: 3.0778\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 735589702937083904.0000 - mean_absolute_error: 735589702937083904.0000 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7552 - mean_absolute_error: 2.7552 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.7551 - mean_absolute_error: 2.7551 - val_loss: 2.7644 - val_mean_absolute_error: 2.7644\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7668 - mean_absolute_error: 2.7668\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 55431709336759804362752.0000 - mean_absolute_error: 55431709336759804362752.0000 - val_loss: 2.7791 - val_mean_absolute_error: 2.7791\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7686 - mean_absolute_error: 2.7686 - val_loss: 2.7641 - val_mean_absolute_error: 2.7641\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7669 - mean_absolute_error: 2.7669 - val_loss: 2.7642 - val_mean_absolute_error: 2.7642\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7666 - mean_absolute_error: 2.7666 - val_loss: 2.7641 - val_mean_absolute_error: 2.7641\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7666 - mean_absolute_error: 2.7666 - val_loss: 2.7641 - val_mean_absolute_error: 2.7641\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.7666 - mean_absolute_error: 2.7666 - val_loss: 2.7641 - val_mean_absolute_error: 2.7641\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.7436 - mean_absolute_error: 2.7436\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 363173.9375 - mean_absolute_error: 363173.9375 - val_loss: 2.6055 - val_mean_absolute_error: 2.6055\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5701 - mean_absolute_error: 2.5701 - val_loss: 2.5786 - val_mean_absolute_error: 2.5786\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 8s 4ms/step - loss: 2.5638 - mean_absolute_error: 2.5638 - val_loss: 2.5726 - val_mean_absolute_error: 2.5726\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5623 - mean_absolute_error: 2.5623 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 8s 4ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 7s 3ms/step - loss: 2.5621 - mean_absolute_error: 2.5621 - val_loss: 2.5725 - val_mean_absolute_error: 2.5725\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5729 - mean_absolute_error: 2.5729\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 7s 3ms/step - loss: 380633.4375 - mean_absolute_error: 380633.4375 - val_loss: 2.6367 - val_mean_absolute_error: 2.6367\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 2ms/step - loss: 2.6250 - mean_absolute_error: 2.6250 - val_loss: 2.6025 - val_mean_absolute_error: 2.6025\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6100 - mean_absolute_error: 2.6100 - val_loss: 2.5975 - val_mean_absolute_error: 2.5975\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.6077 - mean_absolute_error: 2.6077 - val_loss: 2.5969 - val_mean_absolute_error: 2.5969\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.6074 - mean_absolute_error: 2.6074 - val_loss: 2.5968 - val_mean_absolute_error: 2.5968\n",
      "1004/1004 [==============================] - 2s 2ms/step - loss: 2.5722 - mean_absolute_error: 2.5722\n",
      "Epoch 1/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2064495.2500 - mean_absolute_error: 2064495.2500 - val_loss: 2.6436 - val_mean_absolute_error: 2.6436\n",
      "Epoch 2/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5665 - mean_absolute_error: 2.5665 - val_loss: 2.5707 - val_mean_absolute_error: 2.5707\n",
      "Epoch 3/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5562 - mean_absolute_error: 2.5562 - val_loss: 2.5695 - val_mean_absolute_error: 2.5695\n",
      "Epoch 4/100\n",
      "2008/2008 [==============================] - 8s 4ms/step - loss: 2.5543 - mean_absolute_error: 2.5543 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 5/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 6/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 7/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 8/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 9/100\n",
      "2008/2008 [==============================] - 5s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 10/100\n",
      "2008/2008 [==============================] - 6s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "Epoch 11/100\n",
      "2008/2008 [==============================] - 7s 3ms/step - loss: 2.5540 - mean_absolute_error: 2.5540 - val_loss: 2.5693 - val_mean_absolute_error: 2.5693\n",
      "1004/1004 [==============================] - 3s 3ms/step - loss: 2.5815 - mean_absolute_error: 2.5815\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [-1.91272474e+04 -2.56479327e+00 -2.79366128e+00 -2.60708920e+00\n",
      " -2.62507176e+00 -2.86290606e+00             nan             nan\n",
      "             nan -2.57551678e+00]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 8s 3ms/step - loss: 196970.6719 - mean_absolute_error: 196970.6719 - val_loss: 2.5645 - val_mean_absolute_error: 2.5645\n",
      "Epoch 2/100\n",
      "3011/3011 [==============================] - 9s 3ms/step - loss: 2.5550 - mean_absolute_error: 2.5550 - val_loss: 2.5559 - val_mean_absolute_error: 2.5559\n",
      "Epoch 3/100\n",
      "3011/3011 [==============================] - 8s 3ms/step - loss: 2.5511 - mean_absolute_error: 2.5511 - val_loss: 2.5557 - val_mean_absolute_error: 2.5557\n",
      "Epoch 4/100\n",
      "3011/3011 [==============================] - 8s 3ms/step - loss: 2.5509 - mean_absolute_error: 2.5509 - val_loss: 2.5557 - val_mean_absolute_error: 2.5557\n",
      "Epoch 5/100\n",
      "3011/3011 [==============================] - 8s 3ms/step - loss: 2.5509 - mean_absolute_error: 2.5509 - val_loss: 2.5557 - val_mean_absolute_error: 2.5557\n",
      "Epoch 6/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5509 - mean_absolute_error: 2.5509 - val_loss: 2.5557 - val_mean_absolute_error: 2.5557\n",
      "Epoch 7/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5509 - mean_absolute_error: 2.5509 - val_loss: 2.5557 - val_mean_absolute_error: 2.5557\n",
      "Epoch 8/100\n",
      "3011/3011 [==============================] - 7s 2ms/step - loss: 2.5509 - mean_absolute_error: 2.5509 - val_loss: 2.5557 - val_mean_absolute_error: 2.5557\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1331d2f80&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x133825450&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1331d2f80&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x133825450&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1331d2f80&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x1331d2f80&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x1331d2f80>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x133825450>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "461d7494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0006624546927521231, 'n_hidden': 1, 'n_neurons': 36}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29e7a5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.564793268839518"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72f20ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "998534d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/3011 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "907c5f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5938022],\n",
       "       [3.5938022],\n",
       "       [3.5938022],\n",
       "       ...,\n",
       "       [3.5938022],\n",
       "       [3.5938022],\n",
       "       [3.5938022]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6eeb0673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :      2.5484457546463024\n",
      "Mean Squared Error :       75.40833696900332\n",
      "Median Absolute Error :    1.2918022136688232\n",
      "Explained Variance Score : 0.2249331798100721\n",
      "r2-Score :                 0.20382893464151997\n"
     ]
    }
   ],
   "source": [
    "prediction_metrics(y_pred_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3132f90",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "The best model was the Random Forest Regressor with the following statistics:\n",
    "\n",
    "### Cross Validation:\n",
    "* Scores:  0.68802357, 0.28007676, 0.06561844, 0.0558667,  0.04707463, 0.03946168, 0.03526181, 0.04808714, 0.06202095, 0.06453636\n",
    "* Mean:               0.13860280285633117\n",
    "* Standard deviation: 0.19557082408696733\n",
    "\n",
    "\n",
    "### Test Data:\n",
    "* Mean Absolute Error :      0.04189141065507549\n",
    "* Mean Squared Error :       0.06317341583802455\n",
    "* Median Absolute Error :    0.02113960507459816\n",
    "* Explained Variance Score : 0.9432657426983421\n",
    "* r2-Score :                 0.9432657325718565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8615758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
